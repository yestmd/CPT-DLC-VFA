{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import AnovaRM\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(style=\"white\")\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import researchpy as rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st cohort mice (male n=6, excluded mice X-L-7 cannot pass stage 3 and mice W-N-4 finished stage 3 when the other mice finished the task, since they had difficulty to learn the CPT task; female n=4) and 2nd cohort mice (male n=15, female n=7 excluded W-N-4, A-RL-3 jumper, excluded in this cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine 1st and 2nd cohort TOT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load 1st cohort data\n",
    "df_list=[\"...\\\\d2.csv\", \"...\\\\d3.csv\", \"...\\\\d5.csv\"] #replace the \"...\" to a full directory of abetii raw data\n",
    "\n",
    "df_1=pd.DataFrame()\n",
    "for i in df_list:\n",
    "    df_=pd.read_csv(i)\n",
    "    df_1=pd.concat([df_1, df_], ignore_index=True)\n",
    "df_1['cohort']=\"coh1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load 2nd cohort data\n",
    "df_list=[\"...\\\\d1.csv\", \"...\\\\d4.csv\"]#replace the \"...\" to a full directory of abetii raw data\n",
    "\n",
    "df_2=pd.DataFrame()\n",
    "for i in df_list:\n",
    "    df_=pd.read_csv(i)\n",
    "    if len(df_)<8:\n",
    "        print(i)\n",
    "    df_2=pd.concat([df_2, df_], ignore_index=True)\n",
    "df_2['cohort']=\"coh2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### combine 1st and 2nd cohort data\n",
    "df=pd.concat([df_1, df_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert short time to datetime format\n",
    "df.loc[:, \"Schedule run date short\"]=pd.to_datetime(df[\"Schedule run date\"]).dt.date\n",
    "df[\"Schedule run date short\"]=pd.to_datetime(df[\"Schedule run date short\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "# add key by using id and run time\n",
    "df.loc[:, \"key\"]=df['Group ID'] + \"-\" + df[\"Animal ID\"] + \"-\" + df[\"Schedule run date short\"].astype('str') \n",
    "df.loc[:, \"id\"]=df['Group ID'] + \"-\" + df[\"Animal ID\"]+ \"-\" + df['cohort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"gander\"]=np.where(df['Group ID'].isin([\"W\", \"X\", \"Y\", \"Z\"]), \"male\", \"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tot=df[df['dosage']=='tot']\n",
    "df_tot=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test whether include duplicated row\n",
    "t=df[df.duplicated('key', keep=False)].sort_values(by='key')\n",
    "t[\"key\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculated d' and implus parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_calcu(hit, miss):\n",
    "    hr_rate = hit/(hit+miss)\n",
    "    return hr_rate\n",
    "\n",
    "def fr_calcu(mistake, correct_rejection):\n",
    "    fr_rate = mistake/(mistake+correct_rejection)\n",
    "    return fr_rate\n",
    "\n",
    "def d_calcu(hr,fr):\n",
    "    d=norm.ppf(hr)-norm.ppf(fr)\n",
    "    return d  \n",
    "\n",
    "def si_calcu(hr,fr):\n",
    "    si=(hr-fr)/(2*(hr+fr)-pow((hr+fr), 2))\n",
    "    return si\n",
    "\n",
    "def c_calcu(hr,fr):\n",
    "    c=-(norm.ppf(hr)+norm.ppf(fr))/2\n",
    "    return c\n",
    "\n",
    "def ri_calcu(hr,fr):\n",
    "    ri=(hr+fr-1)/(1-pow((hr-fr), 2))\n",
    "    return ri\n",
    "\n",
    "def rp_calcu(centre_ITI_Touches, hit, miss, mistake, correct_rejection, Correction_Trial_Correct_Rejection, Correction_Trial_Mistakes):\n",
    "    rp=100*(centre_ITI_Touches)/(hit+miss+mistake+correct_rejection+Correction_Trial_Correct_Rejection+Correction_Trial_Mistakes)\n",
    "    return rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #another way to replace \"space\" in the column name\n",
    "column_name_list = df_tot.columns.tolist()\n",
    "new_column=[]\n",
    "for i in column_name_list:\n",
    "    i_=i.replace(' ','_')\n",
    "    new_column.append(i_)\n",
    "\n",
    "df_tot.columns=new_column\n",
    "# first_20_session['Environment_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot.rename(columns={'Correct_Choice_Latency_Bin_1_(1-15min)': 'corr_latency_bin_1',\n",
    " 'Correct_Choice_Latency_Bin_2_(15-30min)': 'corr_latency_bin_2',\n",
    " 'Correct_Choice_Latency_Bin_3_(30-45min)': 'corr_latency_bin_3',\n",
    " 'Correct_Choice_Latency_Bin_4_(45-60min)': 'corr_latency_bin_4',\n",
    " 'Correct_Choice_Latency_Bin_5_(60-75min)': 'corr_latency_bin_5',\n",
    " 'Correct_Choice_Latency_Bin_6_(75-90min)': 'corr_latency_bin_6',\n",
    " 'Incorrect_Choice_Latency_Bin_1_(1-15min)': 'incorr_latency_bin_1',\n",
    " 'Incorrect_Choice_Latency_Bin_2_(15-30min)': 'incorr_latency_bin_2',\n",
    " 'Incorrect_Choice_Latency_Bin_3_(30-45min)': 'incorr_latency_bin_3',\n",
    " 'Incorrect_Choice_Latency_Bin_4_(45-60min)': 'incorr_latency_bin_4',\n",
    " 'Incorrect_Choice_Latency_Bin_5_(60-75min)': 'incorr_latency_bin_5',\n",
    " 'Incorrect_Choice_Latency_Bin_6_(75-90min)': 'incorr_latency_bin_6',\n",
    " 'Reward_Retrieval_Latency_Bin_1_(0-15min)':'reward_latency_bin_1',\n",
    " 'Reward_Retrieval_Latency_Bin_2_(15-30min)':'reward_latency_bin_2',\n",
    " 'Reward_Retrieval_Latency_Bin_3_(30-45min)':'reward_latency_bin_3',\n",
    " 'Reward_Retrieval_Latency_Bin_4_(45-60min)':'reward_latency_bin_4',\n",
    " 'Reward_Retrieval_Latency_Bin_5_(60-75min)':'reward_latency_bin_5',\n",
    " 'Reward_Retrieval_Latency_Bin_6_(75-90min)':'reward_latency_bin_6',\n",
    " 'Correct_Choice_Latency_Bin_1_(1-15min)_sd': 'corr_latency_bin_1_sd',\n",
    " 'Correct_Choice_Latency_Bin_2_(15-30min)_sd': 'corr_latency_bin_2_sd',\n",
    " 'Correct_Choice_Latency_Bin_3_(30-45min)_sd': 'corr_latency_bin_3_sd',\n",
    " 'Correct_Choice_Latency_Bin_4_(45-60min)_sd': 'corr_latency_bin_4_sd',\n",
    " 'Correct_Choice_Latency_Bin_5_(60-75min)_sd': 'corr_latency_bin_5_sd',\n",
    " 'Correct_Choice_Latency_Bin_6_(75-90min)_sd': 'corr_latency_bin_6_sd',\n",
    " 'Incorrect_Choice_Latency_Bin_1_(1-15min)_sd': 'incorr_latency_bin_1_sd',\n",
    " 'Incorrect_Choice_Latency_Bin_2_(15-30min)_sd': 'incorr_latency_bin_2_sd',\n",
    " 'Incorrect_Choice_Latency_Bin_3_(30-45min)_sd': 'incorr_latency_bin_3_sd',\n",
    " 'Incorrect_Choice_Latency_Bin_4_(45-60min)_sd': 'incorr_latency_bin_4_sd',\n",
    " 'Incorrect_Choice_Latency_Bin_5_(60-75min)_sd': 'incorr_latency_bin_5_sd',\n",
    " 'Incorrect_Choice_Latency_Bin_6_(75-90min)_sd': 'incorr_latency_bin_6_sd',\n",
    " 'Reward_Retrieval_Latency_Bin_1_(0-15min)_sd': 'reward_latency_bin_1_sd',\n",
    " 'Reward_Retrieval_Latency_Bin_2_(15-30min)_sd': 'reward_latency_bin_2_sd',\n",
    " 'Reward_Retrieval_Latency_Bin_3_(30-45min)_sd': 'reward_latency_bin_3_sd',\n",
    " 'Reward_Retrieval_Latency_Bin_4_(45-60min)_sd': 'reward_latency_bin_4_sd',\n",
    " 'Reward_Retrieval_Latency_Bin_5_(60-75min)_sd': 'reward_latency_bin_5_sd',\n",
    " 'Reward_Retrieval_Latency_Bin_6_(75-90min)_sd': 'reward_latency_bin_6_sd'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col=['15_min_bin_-_No_of_non_correction_trials_(7)',\n",
    " '15_min_bin_-_Left_ITI_Touches_(7)',\n",
    " '15_min_bin_-_Centre_ITI_Touches_(7)',\n",
    " '15_min_bin_-_Right_ITI_Touches_(7)',\n",
    " '15_min_bin_-_Blank_Touches_while_image_shown_(7)',\n",
    " '15_min_bin_-_Hits_(7)',\n",
    " '15_min_bin_-_Misses_(7)',\n",
    " '15_min_bin_-_Mistakes_(7)',\n",
    " '15_min_bin_-_Correct_Rejections_(7)',\n",
    " '15_min_bin_-_Correction_Trial_Correct_Rejections_(7)',\n",
    " '15_min_bin_-_Correction_Trial_Mistakes_(7)']\n",
    "df_tot=df_tot.drop(columns=drop_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caculate d' parameter\n",
    "#### use the p concept to fill out zero value issue in time bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate new column for hr, fr, d, si, c, ri, rp\n",
    "from string import Template\n",
    "#loop 6 different time bin\n",
    "df_list=[df_tot]\n",
    "\n",
    "df=df_tot\n",
    "bin_number=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "for i in bin_number:\n",
    "\n",
    "    #local 3 different time bin column\n",
    "    hit='15_min_bin_-_Hits_(%s)'%(i)\n",
    "    hit_c=df.loc[:, hit]\n",
    "\n",
    "    miss = '15_min_bin_-_Misses_(%s)'%(i)\n",
    "    miss_c=df.loc[:,miss]\n",
    "\n",
    "    mistake = '15_min_bin_-_Mistakes_(%s)'%(i)\n",
    "    mistake_c=df.loc[:,mistake]\n",
    "\n",
    "    correct_rejection='15_min_bin_-_Correct_Rejections_(%s)'%(i)\n",
    "    correct_rejection_c=df.loc[:,correct_rejection]\n",
    "\n",
    "    center_iti_touches = '15_min_bin_-_Centre_ITI_Touches_(%s)'%(i)\n",
    "    center_iti_touches_c=df.loc[:,center_iti_touches]\n",
    "\n",
    "    Correction_Trial_Correct_Rejection = '15_min_bin_-_Correction_Trial_Correct_Rejections_(%s)'%(i)\n",
    "    Correction_Trial_Correct_Rejection_c=df.loc[:,Correction_Trial_Correct_Rejection]\n",
    "\n",
    "    Correction_Trial_Mistakes = '15_min_bin_-_Correction_Trial_Mistakes_(%s)'%(i)\n",
    "    Correction_Trial_Mistakes_c = df.loc[:,Correction_Trial_Mistakes]\n",
    "\n",
    "    #calculat hr and fr first\n",
    "    df.loc[:,'hr_15min_bin_%s'%i]=hr_calcu(hit_c,miss_c)\n",
    "    df.loc[:,'fr_15min_bin_%s'%i]=fr_calcu(mistake_c, correct_rejection_c)\n",
    "df.to_csv(\"...\\\\tot_withzero_hr_fr.csv\")  #replace the \"...\" to a full directory you want to save the file\n",
    "\n",
    "df_zero = df[(df[\"hr_15min_bin_1\"] == 0) |\n",
    "                   (df[\"hr_15min_bin_2\"] == 0) |\n",
    "                   (df[\"hr_15min_bin_3\"] == 0) |\n",
    "                   (df[\"hr_15min_bin_4\"] == 0) |\n",
    "                   (df[\"hr_15min_bin_5\"] == 0) |\n",
    "                   (df[\"hr_15min_bin_6\"] == 0) |\n",
    "                   (df['fr_15min_bin_1'] == 0) |\n",
    "                   (df['fr_15min_bin_2'] == 0) |\n",
    "                   (df['fr_15min_bin_3'] == 0) |\n",
    "                   (df['fr_15min_bin_4'] == 0) |\n",
    "                   (df['fr_15min_bin_5'] == 0) |\n",
    "                   (df['fr_15min_bin_6'] == 0)]\n",
    "\n",
    "df_zero.to_csv(\"...\\\\tot_zero_hr_fr.csv\", index=False) #replace the \"...\" to a full directory you want to save the file\n",
    "\n",
    "for i in bin_number:\n",
    "     #local 3 different time bin column\n",
    "    hit='15_min_bin_-_Hits_(%s)'%(i)\n",
    "    hit_c=df.loc[:, hit]\n",
    "\n",
    "    miss = '15_min_bin_-_Misses_(%s)'%(i)\n",
    "    miss_c=df.loc[:,miss]\n",
    "\n",
    "    mistake = '15_min_bin_-_Mistakes_(%s)'%(i)\n",
    "    mistake_c=df.loc[:,mistake]\n",
    "\n",
    "    correct_rejection='15_min_bin_-_Correct_Rejections_(%s)'%(i)\n",
    "    correct_rejection_c=df.loc[:,correct_rejection]\n",
    "\n",
    "    center_iti_touches = '15_min_bin_-_Centre_ITI_Touches_(%s)'%(i)\n",
    "    center_iti_touches_c=df.loc[:,center_iti_touches]\n",
    "\n",
    "    Correction_Trial_Correct_Rejection = '15_min_bin_-_Correction_Trial_Correct_Rejections_(%s)'%(i)\n",
    "    Correction_Trial_Correct_Rejection_c=df.loc[:,Correction_Trial_Correct_Rejection]\n",
    "\n",
    "    Correction_Trial_Mistakes = '15_min_bin_-_Correction_Trial_Mistakes_(%s)'%(i)\n",
    "    Correction_Trial_Mistakes_c = df.loc[:,Correction_Trial_Mistakes]\n",
    "        \n",
    "    #check if hr or fr is value 0, than replace the zero with p concept.\n",
    "    for e in range(len(df)): \n",
    "        if df.iloc[e]['hr_15min_bin_%s'%i]==0:\n",
    "            #display(df.loc[[e]])\n",
    "            df.at[e, 'hr_15min_bin_%s'%i]=1/(df.iloc[e][hit]+df.iloc[e][miss]+df.iloc[e][mistake]+df.iloc[e][correct_rejection])\n",
    "        if df.iloc[e]['hr_15min_bin_%s'%i]==1:\n",
    "            #display(df.loc[[e]])\n",
    "            df.at[e, 'hr_15min_bin_%s'%i]=(df.iloc[e][hit]+df.iloc[e][miss]+df.iloc[e][mistake]+df.iloc[e][correct_rejection]-1)/(df.iloc[e][hit]+df.iloc[e][miss]+df.iloc[e][mistake]+df.iloc[e][correct_rejection])        \n",
    "        if df.iloc[e]['fr_15min_bin_%s'%i]==0:\n",
    "            #display(df.loc[[e]])\n",
    "            df.at[e, 'fr_15min_bin_%s'%i]=1/(df.iloc[e][hit]+df.iloc[e][miss]+df.iloc[e][mistake]+df.iloc[e][correct_rejection])\n",
    "        if df.iloc[e]['fr_15min_bin_%s'%i]==1:\n",
    "            #display(df.loc[[e]])\n",
    "            df.at[e, 'fr_15min_bin_%s'%i]=(df.iloc[e][hit]+df.iloc[e][miss]+df.iloc[e][mistake]+df.iloc[e][correct_rejection]-1)/(df.iloc[e][hit]+df.iloc[e][miss]+df.iloc[e][mistake]+df.iloc[e][correct_rejection]) \n",
    "        \n",
    "    df.loc[:,'d_15min_bin_%s'%i]=d_calcu(df.loc[:,'hr_15min_bin_%s'%i], df.loc[:,'fr_15min_bin_%s'%i])\n",
    "    df.loc[:,'si_15min_bin_%s'%i]=si_calcu(df.loc[:,'hr_15min_bin_%s'%i], df.loc[:,'fr_15min_bin_%s'%i])\n",
    "    df.loc[:,'c_15min_bin_%s'%i]=c_calcu(df.loc[:,'hr_15min_bin_%s'%i], df.loc[:,'fr_15min_bin_%s'%i])\n",
    "    df.loc[:,'ri_15min_bin_%s'%i]=ri_calcu(df.loc[:,'hr_15min_bin_%s'%i], df.loc[:,'fr_15min_bin_%s'%i])\n",
    "    df.loc[:,'rp_15min_bin_%s'%i]=rp_calcu(center_iti_touches_c, hit_c, miss_c, mistake_c, correct_rejection_c, \n",
    "                                               Correction_Trial_Correct_Rejection_c, Correction_Trial_Mistakes_c)\n",
    "\n",
    "df.loc[:, 'Hit_Rate'] =hr_calcu(df.loc[:, 'End_Summary_-_Hits_(1)'],df.loc[:, 'End_Summary_-_Misses_(1)'])\n",
    "df.loc[:, 'False_Alarm_Rate'] =fr_calcu(df.loc[:, 'End_Summary_-_Mistakes_(1)'], df.loc[:, 'End_Summary_-_Correct_Rejections_(1)'])\n",
    "for e in range(len(df)): \n",
    "    \n",
    "    if df.iloc[e]['Hit_Rate']==0:\n",
    "        trial_n=df.iloc[e]['End_Summary_-_Hits_(1)']+df.iloc[e]['End_Summary_-_Misses_(1)']+df.iloc[e]['End_Summary_-_Mistakes_(1)']+ df.iloc[e]['End_Summary_-_Correct_Rejections_(1)']\n",
    "        df.at[e, 'Hit_Rate']=1/(trial_n)\n",
    "    if df.iloc[e]['Hit_Rate']==1:\n",
    "        trial_n=df.iloc[e]['End_Summary_-_Hits_(1)']+df.iloc[e]['End_Summary_-_Misses_(1)']+df.iloc[e]['End_Summary_-_Mistakes_(1)']+ df.iloc[e]['End_Summary_-_Correct_Rejections_(1)']\n",
    "        df.at[e, 'Hit_Rate']=(trial_n-1)/(trial_n)\n",
    "    \n",
    "    if df.iloc[e]['False_Alarm_Rate']==0:\n",
    "        trial_n=df.iloc[e]['End_Summary_-_Hits_(1)']+df.iloc[e]['End_Summary_-_Misses_(1)']+df.iloc[e]['End_Summary_-_Mistakes_(1)']+ df.iloc[e]['End_Summary_-_Correct_Rejections_(1)']\n",
    "        df.at[e, 'False_Alarm_Rate']=1/(trial_n)\n",
    "    if df.iloc[e]['False_Alarm_Rate']==1:\n",
    "        trial_n=df.iloc[e]['End_Summary_-_Hits_(1)']+df.iloc[e]['End_Summary_-_Misses_(1)']+df.iloc[e]['End_Summary_-_Mistakes_(1)']+ df.iloc[e]['End_Summary_-_Correct_Rejections_(1)']\n",
    "        print(str(e))\n",
    "        df.at[e, 'False_Alarm_Rate']=(trial_n-1)/(trial_n)\n",
    "        \n",
    "df.loc[:, 'c'] =c_calcu(df.loc[:,'Hit_Rate'], df.loc[:,'False_Alarm_Rate'])\n",
    "df.loc[:, 'd'] =d_calcu(df.loc[:,'Hit_Rate'], df.loc[:,'False_Alarm_Rate'])\n",
    "df.loc[:, 'si'] =si_calcu(df.loc[:,'Hit_Rate'], df.loc[:,'False_Alarm_Rate'])\n",
    "df.loc[:, 'ri'] =ri_calcu(df.loc[:,'Hit_Rate'], df.loc[:,'False_Alarm_Rate'])\n",
    "df.loc[:, 'impuls'] =100*(df.loc[:,'End_Summary_-_Centre_ITI_Touches_(1)']/df.loc[:,'trial_by_trial_anal_-_ITI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It contains 0 infinite values\n"
     ]
    }
   ],
   "source": [
    "#check if inf in d' exist\n",
    "df_inf=df[['d_15min_bin_1', 'd_15min_bin_2','d_15min_bin_3','d_15min_bin_4','d_15min_bin_5','d_15min_bin_6']]\n",
    "count = np.isinf(df_inf).values.sum()\n",
    "print(\"It contains \" + str(count) + \" infinite values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"...\\\\df_tot.csv\") #replace the \"...\" to a full directory you want to save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check zero row\n",
    "def get_columns_with_zeros(dataframe):\n",
    "    zero_columns = []\n",
    "    \n",
    "    for column in dataframe.columns:\n",
    "        if (dataframe[column] == 0).any():\n",
    "            zero_columns.append(column)\n",
    "    \n",
    "    return zero_columns\n",
    "\n",
    "get_columns_with_zeros(df_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# built feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_list=[]\n",
    "false_list=[]\n",
    "miss_list=[]\n",
    "hr_list=[]\n",
    "fr_list=[]\n",
    "d_list=[]\n",
    "si_list=[]\n",
    "c_list=[]\n",
    "ri_list=[]\n",
    "rp_list=[]\n",
    "cor_latency_mean=[]\n",
    "incor_latency_mean=[]\n",
    "reward_latency_mean=[]\n",
    "cor_latency_sd=[]\n",
    "incor_latency_sd=[]\n",
    "reward_latency_sd=[]\n",
    "corr_reject_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list=[hit_list,false_list,miss_list, corr_reject_list,\n",
    "        hr_list,fr_list,d_list,si_list,c_list,ri_list,rp_list,\n",
    "        cor_latency_mean,incor_latency_mean,reward_latency_mean,cor_latency_sd,incor_latency_sd,reward_latency_sd]\n",
    "\n",
    "feature_list=[\"15_min_bin_-_Hits_(%s)\",\"15_min_bin_-_Mistakes_(%s)\",\"15_min_bin_-_Misses_(%s)\",'15_min_bin_-_Correct_Rejections_(%s)',\n",
    "\"hr_15min_bin_%s\",\"fr_15min_bin_%s\",\"d_15min_bin_%s\",\"si_15min_bin_%s\",\"c_15min_bin_%s\",\"ri_15min_bin_%s\",\"rp_15min_bin_%s\",\n",
    "\"corr_latency_bin_%s\",\"incorr_latency_bin_%s\",\"reward_latency_bin_%s\",\"corr_latency_bin_%s_sd\",\"incorr_latency_bin_%s_sd\",\"reward_latency_bin_%s_sd\"]\n",
    "\n",
    "for a, i in zip(a_list, feature_list):\n",
    "    for j in [\"1\", \"2\", \"3\", \"4\", \"5\",\"6\"]:\n",
    "        a.append(i%(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare df for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_mean=df_tot.groupby(by=['id','gander', 'cohort'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[df_tot_mean]\n",
    "\n",
    "for j in df_list:\n",
    "    for i in reward_latency_mean:\n",
    "        j[i] = (j[i].astype(str).str.split()).apply(lambda x: float(x[0].replace(',', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_melt=df_tot_mean.melt(id_vars=[\n",
    " 'id','gander', 'cohort'\n",
    " ], var_name=\"param\", value_name=\"value\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_melt[(df_tot_melt['param'].str.contains(\"d\")) & (df_tot_melt['value']==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check inf data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[df_tot_melt]\n",
    "name_list=[\"df_tot_melt\"]\n",
    "for j, i in zip(df_list, name_list):\n",
    "    print()\n",
    "    print(i)\n",
    "    print(\"printing the count of infinity values\")\n",
    "    count = np.isinf(j[\"value\"]).values.sum()\n",
    "    print(\"It contains \" + str(count) + \" infinite values\")\n",
    "    \n",
    "    print()\n",
    "    print(\"printing row index with infinity \")\n",
    "  \n",
    "    r = j[np.isinf(j[\"value\"])]\n",
    "    display(r[r[\"param\"].str.contains(\"15\")])\n",
    "\n",
    "    f = j[j[\"value\"]==0]\n",
    "    display(f[f[\"param\"].str.contains(\"15\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot 15min bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(mean, std, histmax=False, color=\"black\"):\n",
    "    x = np.linspace(mean-4*std, mean+4*std, 200)\n",
    "    p = stats.norm.pdf(x, mean, std)\n",
    "    if histmax:\n",
    "        p = p*histmax/max(p)\n",
    "    z = plt.plot(x, p, color, linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[df_tot_melt]\n",
    "folder_list=[\"tot_15\"]\n",
    "\n",
    "for a, b  in zip(df_list, folder_list):\n",
    "    \n",
    "    for i in a_list:\n",
    "            \n",
    "        df=a[(a[\"param\"].isin(i))].copy()\n",
    "        plot=sns.pointplot(x='param', y='value', hue='gander', hue_order=['male', 'female'],palette=['royalblue', 'coral'], \n",
    "                           data=df, errorbar=('ci', 68)) \n",
    "        plot.set(xlabel=\"\")\n",
    "        plot.set(ylabel=\"\")\n",
    "        title=i[0]+'_'+b\n",
    "        plt.title(title)\n",
    "        print(title)\n",
    "        plt.xticks(rotation = 45, ha='right')\n",
    "        plt.legend(bbox_to_anchor=(1.4, 1),borderaxespad=0)\n",
    "        \n",
    "        save_path = \"...\\\\fig\\\\%s\"%b #replace the \"...\" to a full directory you want to save the file \n",
    "        if os.path.isdir(save_path) == False:\n",
    "            os.mkdir(save_path) \n",
    "        plt.savefig(save_path+'\\%s.png'%(title), dpi=800, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        df.to_csv(save_path+'\\%s.csv'%(title), index=False)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
